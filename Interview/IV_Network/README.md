## 목차

- [1. 🎤 네트워크의 기초](#-네트워크의-기초)
- [2. 🎤 대역폭](#-대역폭)
- [3. 🎤 OSI 7계층](#-osi-7계층)
- [4. 🎤 TCP 의 연결 및 해제 과정 (3,4-way hands shaking)](#-tcp-의-연결-및-해제-과정-34-way-hands-shaking)
- [5. 🎤 DNS & 웹 통신 흐름](#-dns--웹-통신-흐름)
- [6. 🎤 Blocking I/O & Non-Blocking I/O](#-blocking-io--non-blocking-io)
- [7. 🎤 L7, L4 스위치 & 로드밸런싱](#-l7-l4-스위치--로드밸런싱)
- [8. 🎤 HTTP 진화 과정](#-http-진화-과정)
- [9. 🎤 HTTPS](#-https)
- [10. 🎤 쿠키 & 세션](#-쿠키--세션)
- [11. 🎤 프록시 서버](#-프록시-서버)
- [12. 🎤 SOP와 CORS](#-sop와-cors)
- [13. 🎤 네트워크 토폴로지](#-네트워크-토폴로지)
- [14. 🎤 REST API & RESTful](#-rest-api--restful) <br/><br/>

## <span style="color: #FFA500">**🎤 네트워크의 기초**</span>

**Q. 네트워크란 무엇인가요?**

A. 정보를 전송하고, 공유하기 위해 2개 이상의 컴퓨팅 장치를 연결하는 시스템 <br/><br/>

**Q. Network Latency란 무엇인가요?**

A. Network Latency는 데이터 패킷이 송신자에서 수신자까지 전송되는데 걸리는 시간(편도)

→ 양방향 Latency 측정도 있지만, 주로 편도의 용어로 많이 쓰임 <br/><br/>

**Q. PING(Packet InterNet Groper)은 무엇이고, 어떻게 측정하나요?**

A. PING은 네트워크 연결 상태를 진단하기 위해 사용되는 도구입니다.

PING은 요청 패킷을 보내고, 그 목적지로부터 응답 패킷을 받는 것으로 측정합니다.(RTT - Round Trip Time) <br/><br/>

## <span style="color: #FFA500">**🎤 대역폭**</span>

**Q. 만약 트래픽이 100만큼 들어오고 처리량이 50이라면 시스템의 처리과정은 어떻게 되나요?**

A. 시스템은 50의 트래픽만을 처리할 수 있고 나머지 50의 트래픽은 처리되지 않고 버려지거나 대기 상태에 있게 된다. <br/><br/>

**Q.  100Mbps라는 대역폭을 가진 서버가 있고 한 사용자당 100kbps로 동영상 파일을 요청한다고 했을 때, 최대 동접자수는?**

A. 최대 동접자수 : 100Mbps / 100kbps = 약 1000명 <br/><br/>

## <span style="color: #FFA500">**🎤 OSI 7계층**</span>

**Q. *OSI 7 계층으로 나눈 이유가 무엇인가?***

A. 네트워크 통신 과정을 파악하기 쉽게하기 위해 도입되었습니다. 통신과정을 계층별로 표준화해서 다양한 HW/SW에 대해 호환성을 보장할 수 있습니다. 계층별로 표준화가 되어있기 때문에, 특정 과정에 이슈가 있을경우 해당 계층의 이슈만 해결하면됩니다. <br/><br/>

**Q. *Mac 주소란 무엇인가?***

A. NIC의 주소. 네트워크상에서 장비를 구별할 수 있는 고유한 식별자. 48bit로 되어있고, L2에서 사용한다. <br/><br/>

**Q. *라우팅이 무엇인가?***

A. 네트워크 안에서 최적의 경로를 선택하는 과정. L3에서 사용하며, bgp, ospf등 다양한 알고리즘이 있다. <br/><br/>

**Q. *전송 계층에서 사용하는 프로토콜은 무엇이 있는가?***

A. TCP/UDP

TCP는 연결 지향적이고 신뢰할 수 있는 데이터전송을 보장하는 반면, UDP는 비연결형 서비스를 제공하며, 실시간 응용프로그램에서 선호된다. <br/><br/>

**Q. 계층 별로 역할을 설명하라**

A. 

- 물리 계층(1계층): 데이터 전송과 수신을 위한 물리적인 매체와 인터페이스를 제공합니다.
- 데이터 링크 계층(2계층): 물리 계층을 통해 안전하게 데이터를 전송하기 위한 프레이밍, 오류 검출 및 수정 기능을 제공합니다.
- 네트워크 계층(3계층): 다양한 **네트워크 간의 데이터 전송과 라우팅**을 담당합니다.
- 전송 계층(4계층): 종단 간의 신뢰성 있는 **데이터 전송**을 관리합니다.
- 세션 계층(5계층): 응용 프로그램 간의 세션을 생성, 관리, 종료하는 기능을 합니다.
- 표현 계층(6계층): 데이터 형식 변환, **암호화 및 압축**을 담당합니다.
- 응용 계층(7계층): 최종 사용자와 가장 가까운 계층으로, 네트워크 소프트웨어 UI 및 API를 포함합니다. <br/><br/>

**Q. *응용 계층에서 사용되는 프로토콜을 아는 대로 설명하라.***

A. HTTP, FTP, SMTP 등등

HTTP는 웹서버와 클라이언트간 통신을 위해 사용

FTP는 파일 전송을 위해 사용

SMTP는 이메일 전송을 위해 사용 <br/><br/>

## <span style="color: #FFA500">**🎤 TCP 의 연결 및 해제 과정 (3,4-way hands shaking)**</span>

**Q. TCP와 UDP의 차이를 설명해주세요**

A. TCP는 연결 지향적 프로토콜로, 데이터가 정확하게 도착했는지 확인하기 때문에 신뢰성이 높습니다. 반면, UDP는 비연결형 프로토콜로, 데이터의 정확한 전송을 보장하지 않지만 데이터 전송 속도가 빠르다는 장점이 있습니다. <br/><br/>

**Q. 3 way handshake와 4 way handshake를 설명해주세요**

A. 3 way handshake는 TCP 연결을 시작할 때 사용되는 과정입니다. 처음에 클라이언트가 SYN을 통해 연결 요청을 보내면, 서버는 그에 대한 응답으로 ACK플래그를 보냄과 동시에, 연결을 요청하는 SYN플래그를 함께 보냅니다. 그 후 클라이언트가 서버의 SYN에 대한 응답으로 ACK플래그를 보냄으로써 연결을 확립합니다.

4 way handshake는 TCP 연결을 종료할 때 사용되는 과정입니다. 처음에 클라이언트가 FIN플래그를 보내면, 이를 받은 서버가 ACK플래그를 보냅니다. 그 후 서버 역시 연결 해제할 준비를 마치면 FIN플래그를 보내고 이를 받은 클라이언트가 ACK플래그를 보냄으로써 연결을 안전하게 종료합니다. <br/><br/>

**Q. 4 way handshake에서의 TIME-WAIT 상태에 대해서 설명해주세요**

A. TIME-WAIT 상태는 의도치 않은 에러로 인해 연결이 데드락으로 빠지는 것을 방지하기 위한 것입니다. 예를 들어 Server에서 FIN 플래그를 전송하기 전에 전송했던 패킷이 Routing 지연이나 패킷 유실로 인한 재전송 등으로 인해 FIN 패킷보다 늦게 도착하는 상황을 대비해 FIN 플래그를 수신하더라도 일정 시간(Default : 240초)동안 잉여 패킷을 기다리는 과정을 말합니다. 만약 에러로 인해 종료가 지연되다가 시간이 초과되면 CLOSED 상태로 변경됩니다. <br/><br/>

## <span style="color: #FFA500">**🎤 DNS & 웹 통신 흐름**</span>

**Q. https://google.com에 접속했을 때 일어나는 일을 설명해주세요.**

A. 

1) Host가 google.com을 검색하면 OS에서 NIC(network Interface Card, 이거 하나 당 IP하나씩 받을 수 있음)를 통해 요청을 보내야 한다. Host는 google의 IP주소를 알아야 한다.

2) 내가 IP주소를 아는지 모르는지 판단하기 위해 hosts와 DNS cache에서 mapping 정보를 확인한다.(DNS Lookup)

3) 2)에서 없으면 DNS서버로 요청을 보내서 응답을 받는다. (공유기 / 라우터가 DNS를 알고있음. 인터넷 망을 통해 DNS서버로 요청을 한다.)

4) 그 IP주소로 http request를 보내고 응답을 받는다. (해당 IP로 가는 경로는 중간중간의 Router들의 Routing Table에 저장되어있다.) <br/><br/>

**Q. DNS에 대해서 설명해주세요.**

A. DNS(Domain Name System)는 도메인 이름을 IP주소로 변환하거나 그 반대의 역할을 수행하는 시스템입니다. <br/><br/>

## <span style="color: #FFA500">**🎤 Blocking I/O & Non-Blocking I/O**</span>

**Q. Blocking 과 non-Blocking  각각의 정의 설명**

A. 

**Blocking: 단 각 소켓마다 두 가지 버퍼(send, receive)가 있다는 걸 깔고 시작.**

I/O 작업을 요청한 프로세스/스레드는 요청이 완료될 때까지 블락됨

I/O 작업이 진행되는 동안 유저 프로세스가 자신의 작업을 중단한 채, I/O가 끝날 때까지 대기하는 방식

I/O가 호출되면 (I/O 함수가) 제어권을 가져가서 어플리케이션이 멈추게 됨 <br/><br/>

**non-Blocking : 프로세스/스레드를 block시키지 않고, 요청에 대한 현재 상태를 즉시 리턴**

A함수가 I/O 작업을 호출했을 때 I/O 작업이 완료될 대까지 A 함수의 작업을 중단하지 않고 I/O 호출에 대해 즉시 리턴하고, A 함수가 이어서 다른 일을 수행할 수 있도록 하는 방식

제어권을 어플리케이션이 가지고, 어플리케이션은 계속 동작함. 필요한 경우 polling과 같은 상태 확인은 가능

이는 커널이 시스템 콜을 받자마자 CPU 제어권을 다시 어플리케이션에게 넘겨주고, 따라서 어플리케이션은 I/O 작업이 완료되기 전에 다른 작업을 수행할 수 있다. <br/><br/>

**Q. Blocking 방식에서 A함수가 B함수에게 I/O작업을 요청했을 때 요청이 처리되는 방식을 설명해주세요.**

A.

- 어플리케이션(thread)에서 Read()를 호출해 커널에 read I/O를 요청하면, read가 끝날 때까지 application은 block이 되어 다른 작업을 하지 못한다.
- 커널의 I/O 작업이 완료될 때까지 제어권을 커널에서 가지고 있기 때문에, 유저 프로세스는 read I/O가 수행될 때까지는 어플리케이션이 다른 작업을 수행하지 못한다는 것을 의미 <br/><br/>

**Q. non-Blocking 방식에서 A함수가 B함수에게 I/O작업을 요청했을 때 요청이 처리되는 방식을 설명해주세요.**

A. 

- read I/O를 하기 위해 systemcall을 호출하면, kernel 모드로 context-switching된다. 이 때 kernel 모드에서는 read I/O 작업을 실행시킨다. 이후 커널의 I/O 작업 완료 여부와는 무관하게 즉시 응답한다. 아직 리턴할 데이터가 준비되지 않았기 때문에 리눅스 기준으로는 -1 리턴. ( EAGAIN or EWOULDBLOCK 이라는 에러 코드와 함께!)
- 이때 thread는 block I/O와는 다르게 이어서 바로 다른 코드 실행! 원래 내 하던일이나 마저 해야겠다~
- 그렇게 다른 코드를 실행하던 중 kernel 로부터 read 응답이 준비되었다는 신호가 올거야. 그래도 일단 내 하던 일부터 마저 다 끝낸 후에 read non-blocking system call 다시 호출.
- 그럼 다시 kernal 로 context-switching이 되고, 이때는 데이터가 준비된 상태이기 때문에 커널이 다시 user space 쪽으로 데이터를 전송 <br/><br/>

**Q. (희망할 경우에만 준비) 동기/비동기를 나누는 기준이랑 Block/non-Block을 나누는 기준이 어떻게 다른가요?**

A. 

동기와 비동기는 ***작업완료 여부를 신경쓰는가***(완료 여부를 확인하는가)에 따라 달라진다.

- ***동기(Synchronous)***
    - 요청을 보낸 후 return 받아야 다음 동작 실행
    - 현재 작업의 응답이 끝남과 동시에 다음 작업 요청
    - 함수를 호출하는 곳에서 호출되는 함수가 결과를 반환할때까지 대기
    - 작업 완료 여부를 계속해서 확인
- ***비동기(Asynchronous)***
    - 요청을 보낸 후 return과 상관없이 다음 동작 실행
    - 현재 작업의 응답이 끝나지 않은 상태에서 다음 작업 요청
    - 함수를 호출하는 곳에서 결과를 기다리지 않고 다른 함수(callback)에서 결과 처리
    - 작업 완료 여부를 확인하지 않음

블로킹과 넌블로킹은 ***제어권이 넘어오는가***(함수의 리턴시기 및 제어권)에 따라 달라진다.

- ***블로킹(Blocking)***
    - 호출된 함수가 자신의 작업을 모두 끝낼 때까지 제어권을 가지고 있어 호출한 함수가 대기
    - 제어권이 호출된 함수로 넘어감
    - 제어권을 가지게 된 호출된 함수가 작업을 모두 끝낸 후에서야 응답 값과 제어권을 원래 함수로 return
    - 기존 함수는 제어권이 없는 상태라 작업 불가
- ***논블로킹(NonBlocking)***
    - 호출 된 함수가 바로 return 하여 제어권을 돌려주어 호출한 함후에게 다른 작업 수행이 가능하도록
    - 함수가 호출되어도 호출한 함수는 제어권을 넘겨주었다가 바로 돌려받음
    - 기존 함수가 제어권을 가지고 있어 다른 작업 가능 <br/><br/>

## <span style="color: #FFA500">**🎤 L7, L4 스위치 & 로드밸런싱**</span>

**Q.  로드 밸런싱(Load Balancing) 에 대해 설명해주세요.**

A. **서버에 가해지는 부하를 적절하게 분산시켜주는 장치 또는 기술**을 뜻한다. 처음에 구축했던 서버가 수용할 수 있는 범위보다 더 큰 트래픽으로 기존 서버를 사용할 수 없게 되는 경우가 있는데, 이 때 서버 트래픽을 분산시키기 위해 사용한다. <br/><br/>

**Q. 로드 밸런싱 알고리즘에는 뭐가 있나요?** 

A. 라운드로빈, 최소연결, 가중치 분배 알고리즘등 <br/><br/>

Q. 꼬리질문 - 로드 밸런싱 알고리즘 중 대표적인 라운드 로빈, 최소 연결 방식 에 대해 설명해보세요. 

A. **라운드 로빈(Round Robin)** 알고리즘은 서버에 들어오는 요청들을 순서대로 돌아가면서 배정하는 알고리즘이다. 하나씩 배정하기 때문에 여러 대의 서버 성능이 비슷하고 세션이 오래 지속되지 않는 경우에 적합하다.

반면, **최소 연결 방식**(Least Connection Method) 은 요청이 서버에 들어왔을 때 가장 연결이 적은 서버에 배정하는 알고리즘이다. 서버 트래픽이 일정하지 않고 세션이 길어질 때 적합하다. <br/><br/>

**Q. L4 로드 밸런싱과 L7 로드 밸런싱에 대해 설명하고, 차이를 말해보세요.**

A. L4 로드 밸런싱은 Layer 4(네트워크 계층 또는 트랜스포트(전송) 계층) 의 정보를 바탕으로 트래픽을 분산하는 방식이다. TCP, UDP, IP 정보들을 바탕으로 분산한다. 정보가 어떻게 생겼는지 보지 않고 패킷 레벨에서만 트래픽을 분산하기 때문에 속도가 빠르고 효율성이 높으며 L7 로드 밸런싱보다 저렴하다.

반면, L7 로드 밸런싱은 ****Layer 7(애플리케이션(응용) 계층) 의 정보를 바탕으로 요청을 분산한다. HTTP Header, Cookie 등과 같이 사용자가 요청한 정보들을 바탕으로 트래픽을 분산하기 때문에 섬세한 라우팅이 가능하고 비정상적인 트래픽을 판별할 수 있다. 하지만, L4 로드 밸런싱보다 비용이 높다.

## <span style="color: #FFA500">**🎤 HTTP 진화 과정**</span>

**Q. HTTP Protocol의 주요 버전들은 어떤 개선사항을 가지고 있나요?**

A. 

1. **HTTP/0.9 (1991)**:
    - 최초의 HTTP 버전으로, 매우 단순한 프로토콜.
    - 오직 GET 요청만을 지원하며, HTML 문서만을 반환 가능.
2. **HTTP/1.0 (1996)**:
    - HTTP 헤더의 도입으로 요청과 응답이 메타 데이터를 포함할 수 있게 됨.
    - 상태 코드 등을 지원하여 오류 유형을 명확히 구분
3. **HTTP/1.1 (1997, 개선됨 1999)**:
    - 연결 재사용(Keep-Alive)을 통해 여러 요청과 응답이 단일 연결을 통해 이루어질 수 있게 됨.
    - 청크 전송, 압축, 요청 파이프라이닝 등의 기능이 추가됨.
    - 호스트와 같은 새로운 헤더들이 도입되어 가상 호스팅이 가능해짐.
4. **HTTP/2 (2015)**:
    - 프로토콜의 효율성과 속도를 개선하기 위해 도입된 이진 프로토콜.
    - 서버 푸시 기능을 도입하여 서버가 클라이언트의 요청에 더욱 빠르게 응답할 수 있음.
    - 멀티플렉싱을 통해 하나의 연결에서 여러 요청과 응답이 동시에 이루어질 수 있음.
    - 헤더 압축을 통해 프로토콜 오버헤드 감소. <br/><br/>

**Q. HTTP/3 이전 버전과의 주요한 차이가 무엇인지 설명해주세요.**

A.

HTTP/3은 이전 버전들이 TCP를 사용하는 것과는 다르게 UDP 기반의 QUIC 프로토콜을 사용합니다. 이는 몇 가지 주요한 차이점과 이점을 가짐

- **QUIC 프로토콜 사용**: QUIC는 연결 설정 시간을 줄이고, 연결의 재설정과 관련된 지연을 감소시킵니다. 이는 특히 네트워크 환경이 변할 때(예: 사용자가 이동 중일 때) 연결의 안정성을 유지하는 데 도움이 됩니다.
- **내장된 TLS 지원**: QUIC은 기본적으로 TLS 암호화를 내장하여 보안 통신이 기본적으로 제공됩니다. 이전 HTTP 버전에서는 HTTPS를 사용할 때만 TLS가 적용되었습니다.
- **연결 마이그레이션 지원**: 사용자의 IP 주소나 포트가 변경되어도 기존의 연결을 유지할 수 있어 모바일 기기 사용에 효과적입니다.
- **스트림 수준의 오류 복구**: QUIC은 각 스트림이 독립적으로 오류를 복구하므로 전체 연결에 영향을 미치지 않고 특정 스트림의 문제를 해결할 수 있습니다.
- **향상된 연결 및 통신 효율**: HTTP/2의 멀티플렉싱 기능을 개선하여, 패킷 손실이 하나의 스트림에만 영향을 미치고 다른 스트림은 영향받지 않도록 합니다. <br/><br/>

## <span style="color: #FFA500">**🎤 HTTPS**</span>

**Q. HTTP의 어떤 한계점 때문에 HTTPS를 사용하게 되었나요**

1. **평문(암호화 x) 통신이기 때문에 도청 가능**
2. **통신 상대를 확인하지 않기 때문에 위장 가능**
3. **완전성을 증명할 수 없기 때문에 변조 가능** <br/><br/>

**Q. TLS 프로토콜이 하이브리드 암호화 방식을 사용하게된 이유를 말씀해주세요. ( 공통키는 왜 사용했고, 공개키는 왜 사용했으며 어디에 사용했는지 )**

A. 공통키는 데이터의 빠른 전달을 위해 사용하게 되었고, 공개키는 공통키의 부족한 보안을 채워주기 위해 사용하게 되었다. 이때, 공개키는 공통키를 암호화하고 복호화 하는데 사용한다. <br/><br/>

**Q.  TLS 프로토콜이 하이브리드 암호화 방식에 더해서 CA인증을 사용하게된 이유**

A. 공개키는 신원 확인이 안된다는 단점이 있기 때문에 CA인증을 사용하게 되었다. <br/><br/>

## <span style="color: #FFA500">**🎤 쿠키 & 세션**</span>

**Q. 쿠키와 세션의 차이점**

- 쿠키와 세션은 비슷한 역할을 하며, 동작 원리도 비슷하다. 그 이유는 세션도 결국 쿠키를 사용하기 때문이다.
- 큰 차이점은사용자의 정보가 저장되는 위치이다. 쿠키는 서버의 자원을 전혀 사용하지 않으며, 세션은 서버의 자원을 사용한다.
- 보안 면에서 세션이 더 우수하며,쿠키는 클라이언트 로컬에 저장되기 때문에 변질되거나 request에서 스니핑 당할 우려가 있어서 보안에 취약하지만세션은 쿠키를 이용해서 session-id만 저장하고 그것으로 구분하여 서버에서 처리하기 때문에 비교적 보안성이 높다.
- 라이프 사이클은 쿠키도 만료기간이 있지만 파일로 저장되기 때문에 브라우저를 종료해도 정보가 유지될 수 있다. 또한 만료기간을 따로 지정해 쿠키를 삭제할 때까지 유지할 수도 있다.반면에 세션도 만료기간을 정할 수 있지만, 브라우저가 종료되면 만료기간에 상관없이 삭제된다.
- 속도 면에서 쿠키가 더 우수하며,쿠키는 쿠키에 정보가 있기 때문에 서버에 요청 시 속도가 빠르고세션은 정보가 서버에 있기 때문에 처리가 요구되어 비교적 느린 속도를 낸다. <br/><br/>

**Q. 쿠키와 세션을 사용하는 이유는?**

A. 세션이 쿠키에 비해 보안이 높은 편이나 쿠키를 사용하는 이유는 세션은 서버에 저장되고, 서버의 자원을 사용하기에 서버 자원에 한계가 있고, 속도가 느려질 수 있기 때문에 자원관리 차원에서 쿠키와 세션을 적절한 요소 및 기능에 병행 사용하여 서버 자원의 낭비를 방지하며 웹사이트의 속도를 높일 수 있다. <br/><br/>

**Q. 세션의 동작과정에 대해 설명하세요.**

1. 클라이언트가 페이지에 요청한다.
2. 서버는 접근한 클라이언트의 Request-Header 필드인 Cookie를 확인하여, 클라이언트가 해당 session-id를 보냈는지 확인한다.
3. session-id가 존재하지 않는다면 서버는 session-id를 생성해 클라이언트에게 넘겨준다.
4. 클라이언트는 서버로부터 받은 session-id를 쿠키에 저장한다.
5. 클라이언트는 서버에 요청시 이 쿠키의 session-id 값을 같이 서버에 전달한다.
6. 서버는 전달받은 session-id로 session에 있는 클라이언트 정보를 가지고 요청을 처리 후 응답한다. <br/><br/>

**Q. 쿠키의 동작 과정에 대해 설명하세요.**

1. 클라이언트가 페이지를 요청한다. 
2.  (사용자가 웹사이트에 접근)웹 서버는 쿠키를 생성한다.
3. 생성한 쿠키에 정보를 담아 HTTP 화면을 돌려줄 때, 같이 클라이언트에게 돌려준다.
4. 넘겨받은 쿠키는 클라이언트가 가지고 있다가(로컬 PC에 저장) 다시 서버에 요청할 때 요청과 함께 쿠키를 전송한다.
5. 동일 사이트 재방문 시 클라이언트의 PC에 해당 쿠키가 있는 경우, 요청 페이지와 함께 쿠키를 전송한다. <br/><br/>

## <span style="color: #FFA500">**🎤 프록시 서버**</span>

**Q. 프록시 서버란 무엇이고 왜 필요한지 말씀해주세요**

A. 프록시 서버는 클라이언트와 서버 사이에 위치하는 중계 서버로, 클라이언트의 요청을 받아 서버에 전달하고 서버의 응답을 다시 클라이언트에게 전달하는 역할을 합니다. 프록시 서버는 보안 강화, 네트워크 성능 향상, 익명성 보장 등의 목적으로 사용됩니다. 특히 캐싱 기능을 통해 자주 요청하는 리소스를 프록시 서버에 저장해 두었다가 빠르게 제공하여 네트워크 트래픽과 서버 부하를 줄일 수 있습니다. <br/><br/>

**Q. 프록시 서버 사용 시 페이지 내용과 데이터의 값이 계속 바뀌면 어떻게 해야할지 말씀해주세요**

A. 페이지 내용과 데이터의 값이 계속 바뀐다면, 프록시 서버의 캐싱 설정을 조정해야 합니다. 프록시 서버로 사용자가 요청했을 때 요청한 시각이 프록시에서 다운받은 시간에서 만료한 기간 이내면 프록시에서 다운로드 할 것이고, 그렇지 않으면 다시 실제 서버로 요청하게 됩니다. 따라서 자주 바뀌는 데이터라면 캐시의 만료기한을 단축하는 등의 설정이 필요합니다. <br/><br/>

## <span style="color: #FFA500">**🎤 SOP와 CORS**</span>

**Q. SOP와 CORS에 대해서 설명해주세요**

A. 사용자를 CSRF, XSS 등의 공격으로부터 보호하기 위해 1차적인 방어선으로 시행된 **동일 출처 정책 (Same-Origin Policy, SOP)**에 의해 제 3자가 제공하는 API를 직접 호출하기가 어려워졌다. 하지만, 보호를 위해 동일한 출처를 제외하고 모든 외부 리소스를 차단한다면 인터넷이 돌아가지 않을 테니 이런 배경에 의해 리소스 호출이 허용된 출처를 서버가 명시해 놓으면, 출처가 다르더라도 요청과 응답을 주고받을 수 있도록 만들어놓은 정책이 바로 **교차 출처 리소스 공유 (Cross-Origin Resource Sharing, CORS) 이다.** <br/><br/>

**Q. 브라우저가 보안을 위해 SOP를 하는데 하지 않으면 어떤 문제가 발생할지 말씀해주세요.**

A. CSRF 혹은 XSS 같은 악성 스크립트에 의한 공격을 받을 수 있다. <br/><br/>

**Q. CORS 에러는 서버에서 보내는걸까요?**

A. 서버가 요청을 처리하는 방식이나 CORS 정책 구성이 올바르지 않을 때, 브라우저에서 이 에러가 발생하는 것입니다. <br/><br/>

**Q. 출처에 대해서 설명해주세요**

A. 프로토콜 (예: HTTP, HTTPS), 호스트 (도메인), 포트를 포함하는 웹 자원의 고유 식별자입니다. <br/><br/>

**Q. 같은 출처와 다른 출처를 어떻게 구분하는지 설명해주세요**

A. 기본적으로 Protocol, Host, Port가 동일해야 같은 출처라고 합니다. <br/><br/>

**Q. CORS의 동작에 대해 설명해주세요**

A. 크게 3가지의 동작 방식이 있습니다. 가장 기본적으로는 단순 요청이 있는데 이는 조건이 까다롭기 때문에 대부분 사용하지 못하는 방식입니다. 이러한 단순 요청 대신 예비 요청 방식을 사용하는데 이는 미리 예비 요청을 보냄으로써 서버에 **부작용이** 발생하지 않도록 하고 단순요청에서 처리하지 못한 조건들에 대해서 처리를 합니다. 마지막으로 인증된 요청 방식이 있는데 이는, 쿠키, 토큰과 같이 사용자 식별 정보가 담긴 요청에 대해서 조금 더 엄격하게 처리하는 방식입니다. 인증된 요청 역시 예비 요청처럼 preflight가 먼저 일어난다. <br/><br/>

## <span style="color: #FFA500">**🎤 네트워크 토폴로지**</span>

**Q. 스타 토폴로지 정의 / 장점1가지 / 단점1가지**

A. **네트워크 안의 각각의 노드에서 보낸 정보가 목적지에 닿기 위해서는 반드시 중앙 호스트를 지나는 구조**

장점 : 각각의 노드는 중앙 허브와 독립적으로 연결되어 있어서 노드 하나에 장애가 발생하더라도 나머지 네트워크는 영향을 받지 않고 기능한다.

단점 : 중앙 허브에 장애가 생기면, 나머지 네트워크가 모두 멈춘다. <br/><br/>

**Q. 트리 토폴로지 정의 / 장점1가지 / 단점1가지**

A. **노드들은 부모-자식 계층 구조로 연결, 중앙 허브에 연결된 노드는 다른 노드와 선으로 연결되어 있어, 연결된 두 개의 노드는 하나의 연결만을 상호 공유**

장점 : 노드 추가와 네트워크 확장이 쉽다.

단점 : 중앙 허브에 문제가 발생하면, 가지 시스템 내에서는 연결되어 있더라도 가지들 사이의 연결은 끊어진다. <br/><br/>

**Q. 메시 토폴로지 정의 / 장점1가지 / 단점1가지**

A. **노드들을 점 대 점으로 상호 연결한 구조**

장점 : 안정성과 보안성이 뛰어나고, 노드 간에 상호 연결된 정도가 높고 복합적이어서 장애에 강하다.

단점 : 전송 매체 개수 증가에 따라 비용 측면에서 극단적으로 비효율적 <br/><br/>

**Q. 버스 토폴로지 정의 / 장점1가지 / 단점1가지**

A. **네트워크 상의 모든 장치가 하나의 케이블로 연결된 형태**

장점 : 비용 효율적, 소규모 네트워크에 적합

단점 : 데이터가 “반 이중" 방식으로 전달되어 데이터를 동시에 양방향으로 보낼 수 없기 때문에 막대한 트래픽을 전송해야 하는 네트워크라면 이 배치 방식은 최적의 선택이 될 수 X <br/><br/>

**Q. 링 토폴로지 정의 / 장점1가지 / 단점1가지**

A. **호스트의 연결이 순환 고리 구조, 데이터가 원 모양의 네트워크를 따라 한 방향 또는 양방향으로 흐르며 각각의 장치 양옆에는 두 개의 이웃 노드가 꼭 존재.**

장점 : 링 토폴로지에서는 한 번에 하나의 노드에서만 데이터를 전송할 수 있기 때문에 패킷이 충돌할 위험이 거의 없어 데이터를 오류 없이 효율적으로 전송

단점 : 노드를 재설정하거나 추가 또는 제거하기 위해서는 전체 네트워크를 중단해야 한다는 문제. 네트워크 서비스 중단 시간을 예정해야 하는 상황은 비용 발생 <br/><br/>

## <span style="color: #FFA500">**🎤 REST API & RESTful**</span>

**Q 1. REST에 대해 설명해주세요.** <br/><br/>
Q 1-1. 구성요소 <br/><br/>
Q 1-2. 제한 조건(특징) <br/><br/>
Q 1-3. 장단점 ( ++ α ) <br/><br/>

- **RE**presentational **S**tate **T**ransfer의 약자.
- 자원을 정의하고 자원에 대한 주소를 지정하는 네트워크 아키텍처의 모음.
- **자원(Resource)의 표현(Representation)**에 의한 **상태 전달.** <br/><br/>

**REST 구성 요소**

> Resource(자원) - URI모든 자원에 고유한 ID가 존재하고, 이 자원은 Server에 존재한다. 자원을 구별하는 ID는 HTTP URI이다. Client는 URI를 이용해서 자원을 지정하고, 해당 자원의 상태에 대한 조작을 Server에 요청한다.
Verb(행위) - HTTP methodHTTP 프로토콜의 method(POST, GET, DELETE, PUT)를 사용한다.

**REST 아키텍처에 적용되는 제한 조건(특징)**

> 인터페이스 일관성: URI로 지정한 Resource에 대한 조작은 통일되고 한정적인 인터페이스로 수행한다.
무상태(Stateless): 각 요청 간 클라이언트의 context가 Server에 저장되어서는 안 된다. Server는 각각의 요청을 완전히 별개의 것으로 인식하고 처리한다. Seerver의 처리방식에 일관성을 부여하고 부담이 줄어들며, Server의 자유도가 높아진다.
캐시 처리 가능(Cacheable): www에서와 같이 Client는 응답을 캐싱할 수 있어야 한다. 

REST에서 가장 중요한 중심 규칙 2가지

- URI는 정보의 자원을 표현해야 한다.
- 자원의 대한 행위는 HTTP method로 표현한다. <br/><br/>

**장점**

> HTTP 프로토콜의 인프라를 그대로 사용하므로 REST API 사용을 위한 별도의 인프라를 구축할 필요가 없다. 
HTTP 표준 프로토콜을 따르는 모든 플랫폼에서 사용 가능하다. 
API가 의도하는 메시지를 쉽게 파악할 수 있다. 
Server와 Client의 역할을 명확하게 분리한다. 

**단점**

> 표준이 존재하지 않는다. 
사용할 수 있는 method가 제한적이다. 
구형 브라우저가 아직 지원하지 못하는 부분이 있다. 

**Q2. REST API를 설명해주세요
Q2-1. 설계 원칙**

A. REST의 특징을 기반으로 서비스 API를 구현한 것.

- 최근 OpenAPI나 마이크로 서비스를 제공하는 기업 대부분은 REST API를 제공한다.
- **각 요청이 어떤 정보나 동작을 위한 것인지를 그 요청의 모습(URI) 자체로 추론 가능하다.**
- REST API 디자인은 REST의 두 가지 중요 원칙을 지키며 설계한다.
    - URI는 정보의 자원을 표현해야 한다.
    - 자원의 대한 행위는 HTTP method로 표현한다. <br/><br/>

**REST API 설계 원칙**

> URI는 명사를 사용한다.
/로 계층 관계를 표현한다.
URI 마지막 문자로 /를 포함하지 않는다.
URI는 소문자로만 구성한다.HTTP 응답 상태 코드를 사용한다.
파일확장자는 URI에 포함하지 않는다. <br/><br/>

**Q3.  RESTful API에 대해 설명해주세요** 

A. Restful API는 HTTP 통신을 Rest 설계 규칙을 잘 지켜서 개발한 API를 Restful한 API라고 한다.
대표적인 Rest 설계 규칙은 URI는 정보의 자원만 표현해야 하며, 자원의 상태와 행위는 HTTP Method에 명시하는 것 입니다. <br/><br/>